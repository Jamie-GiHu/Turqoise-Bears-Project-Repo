{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turqouise Bears - Jamie Tan, Yasmine Khalifa, Susov Dhakal, Tas Tudor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from scipy.stats import linregress\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from  math import radians, sin, cos, asin, sqrt\n",
    "import re\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victorian Road Crash Statistics and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road statistics are well reported, but are there trends and relationships around preventative measures such as speed limit restrictions, road upgrades and road safety cameras. We will be asking which one is the most effective at preventing incidents and what type of incidents.\n",
    "\n",
    "We will be diving into the data to see if our hypothesis that road upgrades are likely to be the most effective.\n",
    "\n",
    "Key questions to be considered are:\n",
    "\n",
    "Is there a correlation between the number and type of road incidents and the speed limit? Eg - Fatalities / Serious injury / Minor or no injury as classified by VicRoads.\n",
    "Does local government spending improve road conditions to prevent incidents?\n",
    "Does the overall demographics (age / average income / gender) of local government areas have an impact on the number of incidents?\n",
    "Do speed camera locations actually decrease crash numbers within a radius of 1km from the incidents v those outside 1 km of the speed camera?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Socio-economic Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the inital CSV\n",
    "LGA_merged = pd.read_csv(\"lgamerged.csv\")\n",
    "\n",
    "#Split the metro and regional areas for assistance in plotting below\n",
    "LGA_merged_metro = LGA_merged.loc[LGA_merged[\"City_Regional\"] == \"Metro\", :] \n",
    "LGA_merged_regional = LGA_merged.loc[LGA_merged[\"City_Regional\"] == \"Regional\", :] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate and plot the overall statistics for the number of crashes per Local Government Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the DF and then sort the values by total crashes in ascending by LGA\n",
    "total_lga_plot = LGA_merged.copy()\n",
    "total_lga_plot = total_lga_plot.sort_values(\"total_crashes\")\n",
    "\n",
    "#Calculate the average crashes for plotting\n",
    "average_crash_plot = int(total_lga_plot[\"total_crashes\"].mean())\n",
    "print(\"Ave crashes per LGA: \", average_crash_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a horizonal plot by LGA\n",
    "plt.figure(figsize=(12,16))\n",
    "colours = np.where(total_lga_plot[\"City_Regional\"] == \"Metro\", \"r\", \"g\")\n",
    "plt.barh(total_lga_plot[\"LGA\"], total_lga_plot[\"total_crashes\"], color=colours)\n",
    "\n",
    "plt.title('Total Crashes per Local Government Authority (LGA)\\n Victoria 2013-2019', fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Crashes per LGA\", fontsize=12)\n",
    "\n",
    "metro_patch_legend = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "plt.legend(handles=[metro_patch_legend, regional_patch_legend], loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.axvline(x=797, label='Average', c=\"grey\", linestyle=\"--\")\n",
    "plt.annotate('Average',(900,40))\n",
    "\n",
    "plt.gca().xaxis.grid(True, linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore crashes by LGA population for an overall persepective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between total population and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"Total_pop\"], LGA_merged[\"total_crashes\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA\n",
    "summary_slope, summary_int, summary_r, summary_p, summary_std_err = stats.linregress(LGA_merged[\"Total_pop\"], LGA_merged[\"total_crashes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA\n",
    "pop_summary_fit = summary_slope * LGA_merged[\"Total_pop\"] + summary_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Total_pop\"], LGA_merged_metro[\"total_crashes\"], facecolors=[\"red\"], alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Total_pop\"], LGA_merged_regional[\"total_crashes\"], facecolors=[\"green\"], alpha = 0.75)\n",
    "plt.plot(LGA_merged[\"Total_pop\"], pop_summary_fit, \"--\", color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"LGA Population\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes by LGA\", fontsize=12)\n",
    "plt.title(\"Road crashes by population of Local Government Authority\\n Victoria (2013 - 2019)\\n\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_tp = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_tp = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_tp = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_tp, regional_patch_legend_tp, overall_patch_legend_tp], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "\n",
    "plt.annotate('Melbourne',(142500,3560))\n",
    "plt.annotate('Casey',(272000,2450))\n",
    "plt.annotate('Wyndham',(223000,1350))\n",
    "plt.annotate('Geelong',(237000,2300))\n",
    "plt.annotate('Dandenong',(157000,2150))\n",
    "\n",
    "plt.xlim(0,300000)\n",
    "plt.ylim(0,3750)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore total crashes by LGA Index of Relative Socio-Economic Disadvantage (IRSD) - economic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between socio status and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"total_crashes\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Metro)\n",
    "IRSD_slope_m, IRSD_int_m, IRSD_r_m, IRSD_p_m, IRSD_std_err_m = stats.linregress(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Metro)\n",
    "IRSD_summary_fit_m = IRSD_slope_m * LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + IRSD_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY REGIONAL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (regional)\n",
    "IRSD_slope_r, IRSD_int_r, IRSD_r_r, IRSD_p_r, IRSD_std_err_r = stats.linregress(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (regional)\n",
    "IRSD_summary_fit_r = IRSD_slope_r * LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + IRSD_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERALL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA\n",
    "IRSD_slope, IRSD_int, IRSD_r, IRSD_p, IRSD_std_err = stats.linregress(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA\n",
    "IRSD_summary_fit = IRSD_slope * LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + IRSD_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"total_crashes\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"total_crashes\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], IRSD_summary_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], IRSD_summary_fit_r, \"--\", color=\"green\")\n",
    "plt.plot(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], IRSD_summary_fit, \"--\", color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"LGA Index of Relative Socio-Economic Disadvantage (IRSD)\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes by LGA\", fontsize=12)\n",
    "plt.title(\"Road crashes by Local Government Authority (IRSD)\\n Victoria (2013 - 2019)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_IRSD = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_IRSD = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_IRSD = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_IRSD, regional_patch_legend_IRSD, overall_patch_legend_IRSD], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "\n",
    "plt.annotate('Melbourne',(1030,3550))\n",
    "plt.annotate('Dandenong',(900, 2250))\n",
    "plt.annotate('Boorondara',(1068, 493))\n",
    "plt.annotate('Brimbank',(915, 1800))\n",
    "plt.annotate('Casey',(1010, 2450))\n",
    "plt.annotate('Geelong',(996, 2277))\n",
    "\n",
    "plt.xlim(888,1100)\n",
    "plt.ylim(0,3750)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore total crashes by each LGA's median income (not used for presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between socio status and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"Median household income\"], LGA_merged[\"total_crashes\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Metro)\n",
    "med_income_slope_m, med_income_int_m, med_income_r_m, med_income_p_m, med_income_std_err_m = stats.linregress(LGA_merged_metro[\"Median household income\"], LGA_merged_metro[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Metro)\n",
    "med_income_fit_m = med_income_slope_m * LGA_merged_metro[\"Median household income\"] + med_income_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY REGIONAL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Regioanl)\n",
    "med_income_slope_r, med_income_int_r, med_income_r_r, med_income_p_r, med_income_std_err_r = stats.linregress(LGA_merged_regional[\"Median household income\"], LGA_merged_regional[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Regional)\n",
    "med_income_fit_r = med_income_slope_r * LGA_merged_regional[\"Median household income\"] + med_income_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERALL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Overall)\n",
    "med_income_slope, med_income_int, med_income_r, med_income_p, med_income_std_err = stats.linregress(LGA_merged[\"Median household income\"], LGA_merged[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Overall)\n",
    "med_income_fit = med_income_slope * LGA_merged[\"Median household income\"] + med_income_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Median household income\"], LGA_merged_metro[\"total_crashes\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Median household income\"], LGA_merged_regional[\"total_crashes\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged_metro[\"Median household income\"], med_income_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"Median household income\"], med_income_fit_r, \"--\", color=\"green\")\n",
    "plt.plot(LGA_merged[\"Median household income\"], med_income_fit, \"--\", color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"Median Income by LGA\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes by LGA\", fontsize=12)\n",
    "plt.title(\"Road crashes by Local Government Authority (Median Income - 2016)\\n Victoria (2013 - 2019)\\n\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_med = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_med = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_med = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_med, regional_patch_legend_med, overall_patch_legend_med], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "plt.annotate('Melbourne',(1390,3550))\n",
    "plt.annotate('Dandenong',(790, 2150))\n",
    "plt.annotate('Boorondara',(1680, 525))\n",
    "plt.annotate('Brimbank',(990, 1800))\n",
    "plt.annotate('C. Goldfields',(680, 160))\n",
    "plt.annotate('Casey',(1375, 2450))\n",
    "plt.annotate('Geelong',(1075, 2300))\n",
    "\n",
    "plt.xlim(675,1910)\n",
    "plt.ylim(0,3750)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of alcohol incidents by socio economic status of LGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between socio status and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"alcohol\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Overall)\n",
    "booze_slope, booze_int, boze_r, booze_p, booze_std_err = stats.linregress(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"alcohol\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Overall)\n",
    "booze_fit = booze_slope * LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + booze_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Metro)\n",
    "booze_slope_m, booze_int_m, boze_r_m, booze_p_m, booze_std_err_m = stats.linregress(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"alcohol\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Metro)\n",
    "booze_fit_m = booze_slope_m * LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + booze_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY REGIONAL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Regional)\n",
    "booze_slope_r, booze_int_r, boze_r_r, booze_p_r, booze_std_err_r = stats.linregress(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"alcohol\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Regional)\n",
    "booze_fit_r = booze_slope_r * LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + booze_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"alcohol\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"alcohol\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], booze_fit, \"--\", color=\"orange\")\n",
    "plt.plot(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], booze_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], booze_fit_r, \"--\", color=\"green\")\n",
    "\n",
    "plt.xlabel(\"Index of Relative Socio-Economic Disadvantage (IRSD)\", fontsize=12)\n",
    "plt.ylabel(\"Number of alcohol related crashes\\n by LGA\", fontsize=12)\n",
    "plt.title(\"Alcohol Related Road Crashes by\\n Local Government Authority (IRSD) - Victoria (2013 - 2019)\\n\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_booze = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_booze = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_booze = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_booze, regional_patch_legend_booze, overall_patch_legend_booze], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "plt.annotate('Melbourne',(1040,80))\n",
    "plt.annotate('Dandenong',(898, 70))\n",
    "plt.annotate('Boorondara',(1068, 16))\n",
    "plt.annotate('Brimbank',(915, 57))\n",
    "plt.annotate('C. Goldfields',(878, 9))\n",
    "plt.annotate('Casey',(1010, 86))\n",
    "plt.annotate('Geelong',(997, 96))\n",
    "\n",
    "\n",
    "plt.xlim(890,1100)\n",
    "plt.ylim(0,100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of alcohol incidents by people reporting to be of fair or poor health in each LGA (Not used for the presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between the health in a LGA and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"People reporting fair or poor health status\"], LGA_merged[\"total_crashes\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERALL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA\n",
    "health_slope, health_int, health_r, health_p, health_std_err = stats.linregress(LGA_merged[\"People reporting fair or poor health status\"], LGA_merged[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the people of fair or poor health in victoria by LGA\n",
    "health_fit = health_slope * LGA_merged[\"People reporting fair or poor health status\"] + health_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA\n",
    "health_slope_m, health_int_m, health_r_m, health_p_m, health_std_err_m = stats.linregress(LGA_merged_metro[\"People reporting fair or poor health status\"], LGA_merged_metro[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the people of fair or poor health in victoria by LGA\n",
    "health_fit_m = health_slope_m * LGA_merged_metro[\"People reporting fair or poor health status\"] + health_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGIONAL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA\n",
    "health_slope_r, health_int_r, health_r_r, health_p_r, health_std_err_r = stats.linregress(LGA_merged_regional[\"People reporting fair or poor health status\"], LGA_merged_regional[\"total_crashes\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the people of fair or poor health in victoria by LGA\n",
    "health_fit_r = health_slope_r * LGA_merged_regional[\"People reporting fair or poor health status\"] + health_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"People reporting fair or poor health status\"], LGA_merged_metro[\"total_crashes\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"People reporting fair or poor health status\"], LGA_merged_regional[\"total_crashes\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged[\"People reporting fair or poor health status\"], health_fit, \"--\", color=\"orange\")\n",
    "plt.plot(LGA_merged_metro[\"People reporting fair or poor health status\"], health_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"People reporting fair or poor health status\"], health_fit_r, \"--\", color=\"green\")\n",
    "\n",
    "plt.xlabel(\"People reporting fair or poor health status\\n by LGA (%)\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes by LGA\", fontsize=12)\n",
    "plt.title(\"Road crashes by Local Government Authority\\n By people reporting fair or poor health status\\n Victoria (2013 - 2019)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_health = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_health = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_health = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_health, regional_patch_legend_health, overall_patch_legend_health], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "plt.annotate('Melbourne',(0.171,3550))\n",
    "plt.annotate('Dandenong',(.258, 2160))\n",
    "plt.annotate('Boorondara',(0.106, 1440))\n",
    "plt.annotate('Brimbank',(0.243, 1930))\n",
    "plt.annotate('Casey',(0.177, 2470))\n",
    "plt.annotate('Geelong',(0.155, 2280))\n",
    "\n",
    "plt.xlim(0.075,.3)\n",
    "plt.ylim(0,3750)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Represent the crashes per person in an LGA to see if there are more or less crashes per person (cpp) to socio factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between socio status and the number of crashes\n",
    "round(st.pearsonr(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"crash_per_person\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Overall)\n",
    "cpp_slope, cpp_int, cpp_r, cpp_p, cpp_std_err = stats.linregress(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Overall)\n",
    "cpp_fit = cpp_slope * LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + cpp_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Metro)\n",
    "cpp_slope_m, cpp_int_m, cpp_r_m, cpp_p_m, cpp_std_err_m = stats.linregress(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Metro)\n",
    "cpp_fit_m = cpp_slope_m * LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + cpp_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Regional)\n",
    "cpp_slope_r, cpp_int_r, cpp_r_r, cpp_p_r, cpp_std_err_r = stats.linregress(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Regional)\n",
    "cpp_fit_r = cpp_slope_r * LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"] + cpp_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_metro[\"crash_per_person\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], LGA_merged_regional[\"crash_per_person\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], cpp_fit, \"--\", color=\"orange\")\n",
    "plt.plot(LGA_merged_metro[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], cpp_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"Index of Relative Socio-Economic Disadvantage (IRSD)\"], cpp_fit_r, \"--\", color=\"green\")\n",
    "\n",
    "plt.xlabel(\"Index of Relative Socio-Economic Disadvantage (IRSD)\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes per person in LGA\", fontsize=12)\n",
    "plt.title(\"Number of crashes per person in a LGA by\\n Index of Relative Socio-Economic Disadvantage (IRSD)\\n Victoria (2013 - 2019)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_cpp = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_cpp = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_cpp = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_cpp, regional_patch_legend_cpp, overall_patch_legend_cpp], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "plt.annotate('Melbourne',(1030,0.026))\n",
    "plt.annotate('Dandenong',(898, 0.015))\n",
    "plt.annotate('Boorondara',(1068, 0.0075))\n",
    "plt.annotate('Brimbank',(915, 0.0085))\n",
    "plt.annotate('C. Goldfields',(876, .0077))\n",
    "plt.annotate('Casey',(1010, 0.0077))\n",
    "plt.annotate('Murrindindi',(1001, 0.0365))\n",
    "plt.annotate('Mansfield',(1016, 0.0315))\n",
    "plt.annotate('Towong',(999, 0.0245))\n",
    "\n",
    "plt.xlim(888,1100)\n",
    "plt.ylim(0,0.04)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Represent the crashes per person in an LGA to see if there are more or less crashes per person (cpp) for LGA alcohol factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficient to see if there is a correlation between alcohol related incidents\n",
    "#and the number of crashes person (OVERALL)\n",
    "round(st.pearsonr(LGA_merged[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged[\"crash_per_person\"])[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERALL\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Overall)\n",
    "cpp_alcohol_slope, cpp_alcohol_int, cpp_alcohol_r, cpp_alcohol_p, cpp_alcohol_std_err = stats.linregress(LGA_merged[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Overall)\n",
    "cpp_alcohol_fit = cpp_alcohol_slope * LGA_merged[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"] + cpp_alcohol_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Metro)\n",
    "cpp_alcohol_slope_m, cpp_alcohol_int_m, cpp_alcohol_r_m, cpp_alcohol_p_m, cpp_alcohol_std_err_m = stats.linregress(LGA_merged_metro[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged_metro[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Metro)\n",
    "cpp_alcohol_fit_m = cpp_alcohol_slope_m * LGA_merged_metro[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"] + cpp_alcohol_int_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METRO\n",
    "#Calculate the linear regression for the total number of crashes for the population of victoria by LGA (Regional)\n",
    "cpp_alcohol_slope_r, cpp_alcohol_int_r, cpp_alcohol_r_r, cpp_alcohol_p_r, cpp_alcohol_std_err_r = stats.linregress(LGA_merged_regional[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged_regional[\"crash_per_person\"])\n",
    "\n",
    "#Equation of the line to calculate the predicted number of crashes for the population of victoria by LGA (Regional)\n",
    "cpp_alcohol_fit_r = cpp_alcohol_slope_r * LGA_merged_regional[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"] + cpp_alcohol_int_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the linear model on the scatter plot\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.scatter(LGA_merged_metro[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged_metro[\"crash_per_person\"], facecolors=\"red\", alpha = 0.75)\n",
    "plt.scatter(LGA_merged_regional[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], LGA_merged_regional[\"crash_per_person\"], facecolors=\"green\", alpha = 0.75)\n",
    "plt.plot(LGA_merged[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], cpp_alcohol_fit, \"--\", color=\"orange\")\n",
    "plt.plot(LGA_merged_metro[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], cpp_alcohol_fit_m, \"--\", color=\"red\")\n",
    "plt.plot(LGA_merged_regional[\"Clients that received Alcohol & Drug Treatment Services per 1,000 population\"], cpp_alcohol_fit_r, \"--\", color=\"green\")\n",
    "\n",
    "plt.xlabel(\"Clients that received alcohol & drug treatment services per 1,000 population\", fontsize=12)\n",
    "plt.ylabel(\"Number of crashes per peson in LGA\", fontsize=12)\n",
    "plt.title(\"Number of crashes per person by\\n Clients that receive alcohol or drug treatment by LGA\\n Victoria (2013 - 2019)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "metro_patch_legend_cpp_alc = mpatches.Patch(color=\"red\", label=\"Metro\")\n",
    "regional_patch_legend_cpp_alc = mpatches.Patch(color=\"green\", label=\"Regional\")\n",
    "overall_patch_legend_cpp_alc = mpatches.Patch(color=\"orange\", label=\"Victoria\")\n",
    "plt.legend(handles=[metro_patch_legend_cpp_alc, regional_patch_legend_cpp_alc, overall_patch_legend_cpp_alc], loc=\"upper right\", fontsize=11)\n",
    "\n",
    "plt.annotate('Melbourne',(4.2,0.026))\n",
    "plt.annotate('Dandenong',(6.3, 0.0155))\n",
    "plt.annotate(\"B'dara\",(1, 0.0075))\n",
    "plt.annotate('Mansfield',(1.55, 0.0315))\n",
    "plt.annotate('Gannawarra',(17.55, 0.0115))\n",
    "plt.annotate('Murrindindi',(3.6, 0.0365))\n",
    "plt.annotate('Colac-Otway',(7.15, 0.022))\n",
    "plt.annotate('Strathbogie',(2.5, 0.021))\n",
    "plt.annotate('Towong',(0.249, 0.0242))\n",
    "\n",
    "\n",
    "plt.xlim(0,21)\n",
    "plt.ylim(0,0.04)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Work out overall statistics - by age and gender classifications (Young, Older, Middle Aged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the CSV holding condensed information for pie charting the summary statistics\n",
    "grouped_city_or_regional = pd.read_csv(\"groupedregional.csv\")\n",
    "grouped_city_or_regional.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Speed Limit Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into csv file\n",
    "crash_data = pd.read_csv(\"Resources/Crash_Statistics_Victoria_clean.csv\")\n",
    "\n",
    "# Dropping Unnecessary information\n",
    "indexNames = crash_data[crash_data['SPEED_ZONE'] == \"Camping grounds or off road\"].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "indexNames = crash_data[crash_data['SPEED_ZONE'] == \"Not known\"].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "indexNames = crash_data[crash_data['SPEED_ZONE'] == \"Other speed limit\"].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "indexNames = crash_data[crash_data['SPEED_ZONE'] == '75 km/hr'].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "indexNames = crash_data[crash_data['LIGHT_CONDITION'] == 'Dark Street lights unknown'].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "indexNames = crash_data[crash_data['LIGHT_CONDITION'] == 'Unk.'].index\n",
    "crash_data.drop(indexNames , inplace=True)\n",
    "\n",
    "# Removing symbol to convert column to interger\n",
    "crash_data =crash_data.replace(to_replace='km/hr', value='', regex=True)\n",
    "\n",
    "# Changing type to integer for sorting \n",
    "crash_data['SPEED_ZONE'] = crash_data['SPEED_ZONE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of accidents per speed limit\n",
    "crash = crash_data.groupby([\"SPEED_ZONE\"])\n",
    "crash = crash_data.groupby([\"SPEED_ZONE\"]).count()\n",
    "crash =crash['OBJECTID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting crash data\n",
    "speed_chart = crash.plot(kind=\"bar\", title=\"Number of accidents per speed limit\")\n",
    "speed_chart.set_xlabel(\"Speed limit Km/hr\")\n",
    "speed_chart.set_ylabel(\"Number of accidents\")\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of accidents in each speed limit as accident type\n",
    "crash = crash_data.groupby([\"SPEED_ZONE\"])\n",
    "crash_count= crash[\"SEVERITY\"].value_counts()\n",
    "crash_type = pd.DataFrame(crash_count)\n",
    "\n",
    "# Plotting chart showing speed limit to severity\n",
    "c2 = crash_data.groupby([\"SPEED_ZONE\"])\n",
    "crash_count2= crash[\"SEVERITY\"].value_counts().unstack('SEVERITY').fillna(0)\n",
    "c4 = crash_count2.plot(kind='barh', stacked=True, figsize=(15,8), color=['red', 'green', 'orange'])\n",
    "c4.set_ylabel(\"SPEED_ZONE Km/hr\")\n",
    "c4.set_xlabel(\"Number of accidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used bins to test range rather that each speed limit separately \n",
    "bins = [0,51,81,115]\n",
    "names = [\"30-50\",\"60-80\",\"90-110\"]\n",
    "crash_data[\"bins\"] = pd.DataFrame(pd.cut(crash_data[\"SPEED_ZONE\"], bins, labels=names, include_lowest=True))\n",
    "binsdf = crash_data.groupby([\"bins\"])\n",
    "total_count = binsdf[\"SEVERITY\"].value_counts()\n",
    "uniquesn_bindf = pd.DataFrame({ \"Total Count\": total_count})\n",
    "uniquesn_bindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage for plotting 100% bar chart\n",
    "percents_df2 = uniquesn_bindf.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "pd.options.display.float_format = '{:,.2f}%'.format\n",
    "percents_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents_df2.unstack().plot.barh(stacked=True, figsize=(15,8), color=['red', 'green', 'orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of accidents in each speed limit as light condition\n",
    "crash = crash_data.groupby([\"LIGHT_CONDITION\"])\n",
    "crash_count= crash[\"SEVERITY\"].value_counts()\n",
    "c = pd.DataFrame(crash_count)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting chart showing light condition to severity\n",
    "\n",
    "c5 = crash_data.groupby([\"LIGHT_CONDITION\"])\n",
    "crash_count5= c5[\"SEVERITY\"].value_counts().unstack('SEVERITY').fillna(0)\n",
    "c6 = crash_count5.plot(kind='barh', stacked=True, figsize=(15,8), color=['red', 'green', 'orange'])\n",
    "c6.set_ylabel(\"LIGHT CONDITION\")\n",
    "c6.set_xlabel(\"Number of accidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage for plotting 100% bar chart\n",
    "percents_df = c.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "pd.options.display.float_format = '{:,.2f}%'.format\n",
    "percents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Road Repairs & Upgrades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read crash data file and have a peak at the data \n",
    "crash_data = pd.read_csv(\"Resources/Crash_Statistics_Victoria_clean.csv\")\n",
    "#remove NA values based on row\n",
    "crash_data = crash_data.dropna(axis = 0)\n",
    "\n",
    "#load local government expenditure dataset, skip first row, have a look at top few rows of data\n",
    "#LGA =  local government agency\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "localgov = pd.read_csv(\"Resources/lge_cleanfile.csv\", skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate road expenditure per km in each LGA to use for correlation analysis\n",
    "localgov[\"Expense_per_km\"] = localgov[\"Total-expenditure\"] / localgov[\"Total_roadlength\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group LGA dataset by LGA name and count of accidents (OBJECTID), reset index to return a dataframe, subset columns from dataframes to create a smaller dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_accident_perLGA= crash_data.groupby('LGA_NAME')['OBJECTID'].agg('count').reset_index()\n",
    "expense_per_km = localgov[\"Expense_per_km\"]\n",
    "total_expenditure = localgov[\"Total-expenditure\"]\n",
    "total_roadlength = localgov[\"Total_roadlength\"]\n",
    "total_sealedroad_expense = localgov[\"Local Roads - Sealed-expenditure\"]\n",
    "total_sealedroad = localgov[\"Local Roads - Sealed-length\"]\n",
    "\n",
    "#create a dataframe with lga name, expense per km, total expenditure, total road length, total sealed road expense, total length of sealed roads\n",
    "lga_stats = pd.concat([num_accident_perLGA, expense_per_km, total_expenditure, total_roadlength], axis = 1)\n",
    "\n",
    "#remove np.inf and np.nan values from resulting dataframe before plotting\n",
    "lga_stats = lga_stats.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"Expense_per_km\", \"OBJECTID\", \"Total-expenditure\", \"Total_roadlength\"])\n",
    "\n",
    "#calculate correlation coffecient between total road expense and number of accidents\n",
    "round(st.pearsonr(lga_stats[\"Total-expenditure\"],lga_stats[\"OBJECTID\"])[0],2)\n",
    "x_values2 = lga_stats[\"Total-expenditure\"]\n",
    "y_values2 = lga_stats[\"OBJECTID\"] \n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values2, y_values2)\n",
    "\n",
    "#generating the equation\n",
    "regress_values = x_values2 * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "#create the plot and customize \n",
    "plt.scatter(x_values2,y_values2, facecolors = \"red\", alpha = 0.75)\n",
    "plt.plot(x_values2, regress_values,\"--\")\n",
    "#plt.annotate(line_eq,(6,10),fontsize=15,color=\"red\")\n",
    "plt.xlabel('Total expenditure on roads')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title(\"Total Road expenditure vs number of crashes \\n based on each LGA\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group LGA dataset by LGA name and total fatalities (FATALITIES), reset index to return a dataframe, subset columns from dataframes to create a smaller dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatalities_perLGA= crash_data.groupby('LGA_NAME')['FATALITY'].agg('sum').reset_index()\n",
    "expense_per_km = localgov[\"Expense_per_km\"]\n",
    "total_expenditure = localgov[\"Total-expenditure\"]\n",
    "total_roadlength = localgov[\"Total_roadlength\"]\n",
    "total_sealedroad_expense = localgov[\"Local Roads - Sealed-expenditure\"]\n",
    "total_sealedroad = localgov[\"Local Roads - Sealed-length\"]\n",
    "\n",
    "#create a data frame with expenses and fatalities\n",
    "lga_stats = pd.concat([fatalities_perLGA, expense_per_km, total_expenditure, total_roadlength, total_sealedroad, total_sealedroad_expense], axis = 1)\n",
    "#remove np.nan and np.inf values to avoid errors during plotting\n",
    "lga_stats = lga_stats.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"Expense_per_km\", \"FATALITY\", \"Total-expenditure\", \"Total_roadlength\"])\n",
    "\n",
    "#calculate correlation coffecient between total road expense and number of fatalities\n",
    "round(st.pearsonr(lga_stats[\"Total-expenditure\"],lga_stats[\"FATALITY\"])[0],2)\n",
    "\n",
    "#create a correlation plot for total road expense  and number of fatalities\n",
    "x_values5 = lga_stats[\"Total-expenditure\"]\n",
    "y_values5 = lga_stats[\"FATALITY\"] \n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values5, y_values5)\n",
    "\n",
    "#generating equation\n",
    "regress_values = x_values5 * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "#creating plot and customozing\n",
    "plt.scatter(x_values5,y_values5, facecolors = \"red\", alpha = 0.75)\n",
    "plt.plot(x_values5, regress_values,\"--\")\n",
    "#plt.annotate(line_eq,(6,10),fontsize=15,color=\"red\")\n",
    "plt.xlabel('Total expenditure on roads')\n",
    "plt.ylabel('Average number of fatalities')\n",
    "plt.title(\"Total Road expenditure vs number of fatalities \\n based on each LGA\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Road Safety Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in data from prepared files\n",
    "crashstat = pd.read_csv(\"Output/speedcam_analysis.csv\")\n",
    "speedcam = pd.read_csv(\"Output/speedcamera.csv\")\n",
    "locmatrix = pd.read_csv(\"Output/location_matrix.csv\")\n",
    "crashcam = pd.read_csv(\"Output/crash_w_radius.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the closest camera to each crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate distance between 2 sets of coordinates\n",
    "    \n",
    "def calcdistance(cam_lat, cam_lon, crash_lat, crash_lon):\n",
    "    \n",
    "    # Formula to calculate distance\n",
    "    dlat = crash_lat - cam_lat\n",
    "    dlon = crash_lon - cam_lon\n",
    "    a = sin(dlat/2)**2 + cos(cam_lat) * cos(crash_lat) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371.01 # Radius of the earth in kilometers\n",
    "    d = c * r\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the radians for the given coordinates for both the camera and crash locations\n",
    "\n",
    "%%time\n",
    "\n",
    "locmatrix[\"distance\"] = locmatrix[[\"lat_R\", \"lng_R\", \"LATITUDE_R\", \"LONGITUDE_R\"]].apply(lambda row: calcdistance(row[\"lat_R\"], row[\"lng_R\"], row[\"LATITUDE_R\"], row[\"LONGITUDE_R\"]), axis=1)\n",
    "\n",
    "locmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the shortest distance between accident and camera\n",
    "\n",
    "locmatrix = locmatrix.sort_values(\"distance\", ascending=True)\n",
    "locmatrix = locmatrix.drop_duplicates(subset=[\"OBJECTID\",\"camera_type\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the shortest distance and camera information into the crash statistics data\n",
    "\n",
    "crashcam = crashstat.merge(locmatrix, on=\"OBJECTID\", suffixes=('','_y'))\n",
    "crashcam = crashcam.drop(columns=[\"LATITUDE_y\",\"LONGITUDE_y\",\"postcode_y\"\n",
    "                        ,\"lat_y\",\"lng_y\",\"LATITUDE_R\",\n",
    "                       \"LONGITUDE_R\",\"lat_R\",\"lng_R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each accident as within 1 km radius or outside 1 km radius\n",
    "\n",
    "radius = 1.00 # Metric: Kilometer\n",
    "crashcam[\"1km_radius\"] = np.where(crashcam[\"distance\"]<=radius, \"Y\", \"N\")\n",
    "#crashcam.to_csv(\"Output/crash_w_radius.csv\", encoding=\"utf-8\", index=False)\n",
    "crashcam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap for ALL road incidents in Victoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = crashcam[[\"OBJECTID\",\"ROAD_GEOMETRY\",\"LGA_NAME\",\"FATALITY\",\"LATITUDE\",\"LONGITUDE\",\"SEVERITY\",\"camera_type\",\"1km_radius\"]]\n",
    "\n",
    "heat_all = heat[[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "heat_all = [[row[\"LATITUDE\"], row[\"LONGITUDE\"]] for index, row in\n",
    "                 heat_all.iterrows()]\n",
    "\n",
    "ma = folium.Map([-37.503995, 145.264296], tiles=\"CartoDB positron\", zoom_start=7)\n",
    "HeatMap(heat_all).add_to(ma)\n",
    "ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FATALITIES caused by road incidents in Victoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct heatmap\n",
    "\n",
    "heat = heat[heat[\"FATALITY\"]>0]\n",
    "\n",
    "heat_fatal_all = heat[[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "heat_fatal_all = [[row[\"LATITUDE\"], row[\"LONGITUDE\"]] for index, row in\n",
    "                 heat_fatal_all.iterrows()]\n",
    "\n",
    "m = folium.Map([-37.503995, 145.264296], tiles=\"CartoDB positron\", zoom_start=7)\n",
    "HeatMap(heat_fatal_all).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of fatalities split by road geometry\n",
    "\n",
    "crashcam_fatal = crashcam[crashcam[\"FATALITY\"]>0]\n",
    "\n",
    "grouproadgeo = crashcam_fatal.groupby([\"ROAD_GEOMETRY\"])\n",
    "byroadgeo = grouproadgeo[\"FATALITY\"].sum()\n",
    "pc_byroadgeo = byroadgeo/sum(byroadgeo)*100\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "                        \"Fatality Count\": byroadgeo,\n",
    "                        \"% by Road Geometry\": pc_byroadgeo\n",
    "                        })\n",
    "\n",
    "summary[\"Fatality Count\"] = summary[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary[\"% by Road Geometry\"] = summary[\"% by Road Geometry\"].map('{:,.2f}'.format)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of fatalities split by road geometry and accident type\n",
    "\n",
    "grouproadgeo = crashcam_fatal.groupby([\"ROAD_GEOMETRY\",\"ACCIDENT_TYPE\"])\n",
    "byroadgeo = grouproadgeo[\"FATALITY\"].sum()\n",
    "pc_byroadgeo = byroadgeo/sum(byroadgeo)*100\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "                        \"Fatality Count\": byroadgeo,\n",
    "                        \"% by Road Geometry\": pc_byroadgeo\n",
    "                        })\n",
    "\n",
    "summary[\"Fatality Count\"] = summary[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary[\"% by Road Geometry\"] = summary[\"% by Road Geometry\"].map('{:,.2f}'.format)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fatalities within 1 km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct heatmap\n",
    "\n",
    "heat_1km = heat[heat[\"1km_radius\"]==\"Y\"]\n",
    "heat_1km = heat_1km[[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "heat_1km = [[row[\"LATITUDE\"], row[\"LONGITUDE\"]] for index, row in\n",
    "            heat_1km.iterrows()]\n",
    "m_1km = folium.Map([-37.503995, 145.264296], tiles=\"CartoDB positron\", zoom_start=7)\n",
    "HeatMap(heat_1km).add_to(m_1km)\n",
    "m_1km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fatalities outside 1 km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat__not_1km = heat[heat[\"1km_radius\"]==\"N\"]\n",
    "heat__not_1km = heat__not_1km[[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "heat__not_1km = [[row[\"LATITUDE\"], row[\"LONGITUDE\"]] for index, row in\n",
    "            heat__not_1km.iterrows()]\n",
    "m_not_1km = folium.Map([-37.503995, 145.264296], tiles=\"CartoDB positron\", zoom_start=7)\n",
    "HeatMap(heat__not_1km).add_to(m_not_1km)\n",
    "m_not_1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics grouped by within or out of 1km radius\n",
    "\n",
    "group_radius = crashcam.groupby([\"1km_radius\"])\n",
    "fatality = group_radius[\"FATALITY\"].sum()\n",
    "vehicles = group_radius[\"NO_OF_VEHICLES\"].sum()\n",
    "passengervehicle = group_radius[\"PASSENGERVEHICLE\"].sum()\n",
    "proportion_passengervehicle = passengervehicle/vehicles*100\n",
    "proportion_fatality = fatality/sum(fatality)*100\n",
    "avgdistance = group_radius[\"distance\"].mean()\n",
    "\n",
    "summary_radius = pd.DataFrame({\n",
    "                                \"Fatality Count\": fatality,\n",
    "                                \"% Fatality\": proportion_fatality,\n",
    "                                \"Vehicle Count\": vehicles,\n",
    "                                \"Passenger Vehicle Count\": passengervehicle,\n",
    "                                \"% Passenger Vehicle\": proportion_passengervehicle,\n",
    "                                \"Average Distance\": avgdistance\n",
    "                                })\n",
    "\n",
    "summary_radius[\"Fatality Count\"] = summary_radius[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary_radius[\"Vehicle Count\"] = summary_radius[\"Vehicle Count\"].map('{:,.0f}'.format)\n",
    "summary_radius[\"Passenger Vehicle Count\"] = summary_radius[\"Passenger Vehicle Count\"].map('{:,.0f}'.format)\n",
    "summary_radius[\"% Passenger Vehicle\"] = summary_radius[\"% Passenger Vehicle\"].map('{:,.2f}'.format)\n",
    "summary_radius[\"% Fatality\"] = summary_radius[\"% Fatality\"].map('{:,.2f}'.format)\n",
    "summary_radius[\"Average Distance\"] = summary_radius[\"Average Distance\"].map('{:,.2f}km'.format)\n",
    "\n",
    "summary_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statisitics grouped by within or out of 1km radius and road geometry\n",
    "\n",
    "group_camtype_region_radius = crashcam.groupby([\"1km_radius\",\"ROAD_GEOMETRY\"])\n",
    "fatality = group_camtype_region_radius[\"FATALITY\"].sum()\n",
    "proportion_fatality_bytype = fatality/fatality.groupby([\"1km_radius\"]).sum()*100\n",
    "\n",
    "summary_camtype_region_radius = pd.DataFrame({\n",
    "                                \"Fatality Count\": fatality,\n",
    "                                \"% Fatality by Type\": proportion_fatality_bytype\n",
    "                                })\n",
    "\n",
    "summary_camtype_region_radius[\"Fatality Count\"] = summary_camtype_region_radius[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary_camtype_region_radius[\"% Fatality by Type\"] = summary_camtype_region_radius[\"% Fatality by Type\"].map('{:,.2f}%'.format)\n",
    "\n",
    "summary_camtype_region_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statisitics grouped by within or out of 1km radius and RMA\n",
    "\n",
    "group_camtype_region_radius = crashcam.groupby([\"1km_radius\",\"RMA\"])\n",
    "fatality = group_camtype_region_radius[\"FATALITY\"].sum()\n",
    "proportion_fatality_bytype = fatality/fatality.groupby([\"1km_radius\"]).sum()*100\n",
    "\n",
    "summary_camtype_region_radius = pd.DataFrame({\n",
    "                                \"Fatality Count\": fatality,\n",
    "                                \"% Fatality by Type\": proportion_fatality_bytype\n",
    "                                })\n",
    "\n",
    "summary_camtype_region_radius[\"Fatality Count\"] = summary_camtype_region_radius[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary_camtype_region_radius[\"% Fatality by Type\"] = summary_camtype_region_radius[\"% Fatality by Type\"].map('{:,.2f}%'.format)\n",
    "\n",
    "summary_camtype_region_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Welch test to determine if speed cameras are effective in reducing road toll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null hypothesis: Cameras have no effect on fatalities\n",
    "#Alternative hypothesis: Cameras can help save lives \n",
    "\n",
    "st.ttest_ind(crashcam['FATALITY'][crashcam['1km_radius'] == 'Y'],\n",
    "             crashcam['FATALITY'][crashcam['1km_radius'] == 'N'],\n",
    "            equal_var=False)\n",
    "\n",
    "#We can reject null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at data by camera type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics grouped by within or out of 1km radius and camera_type\n",
    "\n",
    "group_camtype_radius = crashcam.groupby([\"camera_type\",\"1km_radius\"])\n",
    "accidents = group_camtype_radius[\"OBJECTID\"].count()\n",
    "fatality = group_camtype_radius[\"FATALITY\"].sum()\n",
    "avgdistance = group_camtype_radius[\"distance\"].mean()\n",
    "vehicles = group_camtype_radius[\"NO_OF_VEHICLES\"].sum()\n",
    "proportion_accidents_bytype = accidents/accidents.groupby([\"camera_type\"]).sum()*100\n",
    "proportion_fatality_bytype = fatality/fatality.groupby([\"camera_type\"]).sum()*100\n",
    "proportion_accidents = accidents/sum(accidents)*100\n",
    "proportion_fatality = fatality/sum(fatality)*100\n",
    "\n",
    "summary_camtype_radius = pd.DataFrame({\n",
    "                                \"Accident Count\": accidents,\n",
    "                                \"Fatality Count\": fatality,\n",
    "                                \"Average Distance\": avgdistance,\n",
    "                                \"Vehicle Count\": vehicles,\n",
    "                                \"% Accident by Type\": proportion_accidents_bytype,\n",
    "                                \"% Fatality by Type\": proportion_fatality_bytype,\n",
    "                                \"% Accident\": proportion_accidents,\n",
    "                                \"% Fatality\": proportion_fatality\n",
    "                                })\n",
    "\n",
    "summary_camtype_radius[\"Accident Count\"] = summary_camtype_radius[\"Accident Count\"].map('{:,.0f}'.format)\n",
    "summary_camtype_radius[\"Fatality Count\"] = summary_camtype_radius[\"Fatality Count\"].map('{:,.0f}'.format)\n",
    "summary_camtype_radius[\"Average Distance\"] = summary_camtype_radius[\"Average Distance\"].map('{:,.2f}km'.format)\n",
    "summary_camtype_radius[\"Vehicle Count\"] = summary_camtype_radius[\"Vehicle Count\"].map('{:,.0f}'.format)\n",
    "summary_camtype_radius[\"% Accident by Type\"] = summary_camtype_radius[\"% Accident by Type\"].map('{:,.2f}%'.format)\n",
    "summary_camtype_radius[\"% Fatality by Type\"] = summary_camtype_radius[\"% Fatality by Type\"].map('{:,.2f}%'.format)\n",
    "summary_camtype_radius[\"% Accident\"] = summary_camtype_radius[\"% Accident\"].map('{:,.2f}%'.format)\n",
    "summary_camtype_radius[\"% Fatality\"] = summary_camtype_radius[\"% Fatality\"].map('{:,.2f}%'.format)\n",
    "\n",
    "summary_camtype_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise difference between camera types in a horizontal bar chart\n",
    "\n",
    "group_camtype_radius = crashcam.groupby([\"camera_type\",\"1km_radius\"])\n",
    "fatality = pd.DataFrame(group_camtype_radius[\"FATALITY\"].sum())\n",
    "fatality = fatality.reset_index()\n",
    "\n",
    "plot = fatality.pivot(index=\"camera_type\", columns=\"1km_radius\")\n",
    "plot = plot.apply(lambda x: x*100/sum(x), axis=1)\n",
    "\n",
    "ax = plot.plot(kind=\"barh\",stacked=True, color=[\"red\",\"green\"])\n",
    "plt.legend([\"Camera Outside 1km Radius\", \"Camera Within 1km Radius\"])\n",
    "plt.title(\"Number of Fatality by Distance from Cameras\")\n",
    "plt.ylabel(\"Camera Type\")\n",
    "plt.xlabel(\"% Number of Fatality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot density graph by nearest distance by camera type\n",
    "\n",
    "value = \"distance\"\n",
    "\n",
    "fatality_no = crashcam_fatal.pivot(index=\"OBJECTID\", columns=\"camera_type\")\n",
    "fatality_no.reset_index(inplace=True)\n",
    "\n",
    "freeway = pd.DataFrame(fatality_no[\"OBJECTID\"])\n",
    "freeway[value] = fatality_no[value][\"Freeway\"]\n",
    "freeway[\"ROAD_GEOMETRY\"] = fatality_no[\"ROAD_GEOMETRY\"][\"Freeway\"]\n",
    "freeway[\"1km_radius\"] = fatality_no[\"1km_radius\"][\"Freeway\"]\n",
    "freeway = freeway.dropna(subset=[value])\n",
    "freeway = freeway.reset_index()\n",
    "\n",
    "wetfilm = pd.DataFrame(fatality_no[\"OBJECTID\"])\n",
    "wetfilm[value] = fatality_no[value][\"Wet film\"]\n",
    "wetfilm[\"ROAD_GEOMETRY\"] = fatality_no[\"ROAD_GEOMETRY\"][\"Wet film\"]\n",
    "wetfilm[\"1km_radius\"] = fatality_no[\"1km_radius\"][\"Wet film\"]\n",
    "wetfilm = wetfilm.dropna(subset=[value])\n",
    "wetfilm = wetfilm.reset_index()\n",
    "\n",
    "p2p = pd.DataFrame(fatality_no[\"OBJECTID\"])\n",
    "p2p[value] = fatality_no[value][\"Point to point\"]\n",
    "p2p[\"ROAD_GEOMETRY\"] = fatality_no[\"ROAD_GEOMETRY\"][\"Point to point\"]\n",
    "p2p[\"1km_radius\"] = fatality_no[\"1km_radius\"][\"Point to point\"]\n",
    "p2p = p2p.dropna(subset=[value])\n",
    "p2p = p2p.reset_index()\n",
    "\n",
    "intersections = ['T intersection', 'Cross intersection',\n",
    "                'Multiple intersection','Y intersection']\n",
    "intersection = pd.DataFrame(fatality_no[\"OBJECTID\"])\n",
    "intersection[value] = fatality_no[value][\"Intersection\"]\n",
    "intersection[\"ROAD_GEOMETRY\"] = fatality_no[\"ROAD_GEOMETRY\"][\"Intersection\"]\n",
    "intersection[\"1km_radius\"] = fatality_no[\"1km_radius\"][\"Intersection\"]\n",
    "intersection = intersection.dropna(subset=[value])\n",
    "intersection = intersection[intersection[\"ROAD_GEOMETRY\"].isin(intersections)]\n",
    "intersection = intersection.reset_index()\n",
    "\n",
    "camtypes = [freeway[value], wetfilm[value], p2p[value], intersection[value]]\n",
    "label = [\"Freeway\", \"Wet Film\", \"Point to Point\", \"Intersection\"]\n",
    "\n",
    "types=0\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "for camtype in camtypes:\n",
    "    \n",
    "    sns.distplot(camtype,\n",
    "                hist=False,\n",
    "                kde=True, \n",
    "                kde_kws={'linewidth': 3},\n",
    "                label=label[types]\n",
    "                )\n",
    "        \n",
    "    types=types+1\n",
    "\n",
    "plt.legend(title=\"Camera Type\")\n",
    "plt.title(\"Density Plot of Distance of Fatal Accidents from Nearest Camera\")\n",
    "plt.xlabel(\"Distance (km)\")\n",
    "plt.ylabel(\"Density of Fatal Accidents\")\n",
    "plt.xlim(-5,35)\n",
    "plt.ylim(0,0.33)\n",
    "plt.axvline(1, color=\"black\", linewidth=3, ls=':')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashcam_fatal = crashcam[crashcam[\"FATALITY\"]>0]\n",
    "\n",
    "g = sns.PairGrid(crashcam_fatal, vars=[\"FATALITY\",\"distance\",\"postcode\"],\n",
    "                hue=\"1km_radius\", palette=([\"green\",\"red\"]))\n",
    "g.map(plt.scatter, alpha=0.7)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANOVA to test if performance is equal between camera types in reducing road toll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null hypothesis: All camera types are equal in preventing road fatalities\n",
    "#Alternative hypothesis: At least one camera type is more or less effective than other camera types\n",
    "\n",
    "#Dependent variable = camera_type\n",
    "#Independent variable = fatality\n",
    "\n",
    "stats.f_oneway(crashcam_fatal['FATALITY'][crashcam_fatal['camera_type'] == 'Freeway'],\n",
    "               crashcam_fatal['FATALITY'][crashcam_fatal['camera_type'] == 'Wet film'],\n",
    "               crashcam_fatal['FATALITY'][crashcam_fatal['camera_type'] == 'Point to point'],\n",
    "               crashcam_fatal['FATALITY'][crashcam_fatal['camera_type'] == 'Intersection'])\n",
    "\n",
    "#At pvalue of 0.5 which is significantly greater than pvalue 0.05, we are not able to reject our Null Hypothesis.\n",
    "#Therefore, at least one camera type is more or less effective than other camera types "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
